I"
<div style="text-align: center;">
     <img src="/assets/img/InfoGAIL/abstract.png" width="90%" />
</div>

<h1 id="abstract">Abstract</h1>

<p>모방학습(Imitation Learning)의 목표는 명시적인 보상 신호에 대한 접근 없이도 전문자의 행동을 모방할 수 있는 것이다. 인간 전문가의 시연은 잠재적인 요인으로 인해 명확한 차이들을 보이며 이는 보통 명시적으로 모델링이 되어있지 않다. 본 논문에서는 전문가 시연의 잠재적인 구조를 비지도 학습 방법을 통해 추론할 수 있는 새로운 알고리즘을 소개한다. GAIL(Generative Adversarial Imitation Learning)을 근간으로 하는 이 방법은 복잡한 행동을 모방할 수 있을뿐만 아니라, 시각적 시연을 포함한 복잡한 행동 데이터에 대한 해석적이고도 의미있는 표현(Representation)을 학습할 수 있게 해준다. 주행 도메인에서는 사람의 시연으로부터 학습된 모델이 다양한 행동을 생성하고 raw visual input을 이용해 사람의 행동을 정확하게 예측할 수 있음을 보여주었다. 다양한 baseline과 비교해볼 때, 본 방법은 전문가 시연 아래 잠재적인 구조를 더욱 잘 파악할 수 있으며 대부분의 경우 데이터마다의 차이로부터 비롯되는 의미있는 요인을 복구할 수 있다.</p>

<blockquote>
  <p>당시 Imitation Learning(IL) 연구의 흐름을 토대로 볼때, GAIL에 다른 요소를 추가하여 새로운 알고리즘인 InfoGAIL을 고안한 것으로 보임. 전문가 시연 데이터마다 전문가들의 성격?, 스타일? 등이 다를텐데 그 속에 내제된 잠재 구조에 대해서 파악하고, 복잡한 task(자율주행)에 대해서 오직 raw image input을 받아 학습할 수 있다는 장점이 있는 것으로 보임.</p>
</blockquote>

<h1 id="1-introduction">1. Introduction</h1>

<p>Reinforcement Learning(RL)의 가장 큰 한계점은 사전에 정의된 보상 함수 혹은 보상 신호를 최적화하는 과정을 포함하는 것이다. 체스나 바둑과 같은 경우는 보상 함수를 명시적으로 정의하는게 적합할 수 있다. 하지만, 이보다 복잡하고, 환경에 대한 구체화가 잘 되어있지 않은 자율 주행과 같은 경우에는 적합한 보상함수의 설계가 어려워질 수 있다.</p>

<p><br /><br /></p>

<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="ybkim95" data-color="#FFDD00" data-emoji="" data-font="Comic" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#000000" data-coffee-color="#ffffff"></script>

:ET