I"<div style="text-align: center;">
    <img src="/assets/img/InfoGAIL/abstract.png" width="90%" />
</div>

<h1 id="abstract">Abstract</h1>

<p>모방학습(Imitation Learning)의 목표는 명시적인 보상 신호에 대한 접근 없이도 전문자의 행동을 모방할 수 있는 것이다. 인간 전문가의 시연은 잠재적인 요인으로 인해 명확한 차이들을 보이며 이는 보통 명시적으로 모델링이 되어있지 않다. 본 논문에서는 전문가 시연의 잠재적인 구조를 비지도 학습 방법을 통해 추론할 수 있는 새로운 알고리즘을 소개한다. GAIL(Generative Adversarial Imitation Learning)을 근간으로 하는 이 방법은 복잡한 행동을 모방할 수 있을뿐만 아니라, 시각적 시연을 포함한 복잡한 행동 데이터에 대한 해석적이고도 의미있는 표현(Representation)을 학습할 수 있게 해준다. 주행 도메인에서는 사람의 시연으로부터 학습된 모델이 다양한 행동을 생성하고 raw visual input을 이용해 사람의 행동을 정확하게 예측할 수 있음을 보여주었다. 다양한 baseline과 비교해볼 때, 본 방법은 전문가 시연 아래 잠재적인 구조를 더욱 잘 파악할 수 있으며 대부분의 경우 데이터마다의 차이로부터 비롯되는 의미있는 요인을 복구할 수 있다.</p>

<blockquote>
  <p>당시 Imitation Learning(IL) 연구의 흐름을 토대로 볼때, GAIL에 다른 요소를 추가하여 새로운 알고리즘인 InfoGAIL을 고안한 것으로 보임. 전문가 시연 데이터마다 전문가들의 성격?, 스타일? 등이 다를텐데 그 속에 내제된 잠재 구조에 대해서 파악하고, 복잡한 task(자율주행)에 대해서 오직 raw image input을 받아 학습할 수 있다는 장점이 있는 것으로 보임.</p>
</blockquote>

<h1 id="1-introduction">1. Introduction</h1>

<p>Reinforcement Learning(RL)의 가장 큰 한계점은 사전에 정의된 보상 함수 혹은 보상 신호를 최적화하는 과정을 포함하는 것이다. 체스나 바둑과 같은 경우는 보상 함수를 명시적으로 정의하는게 적합할 수 있다. 하지만, 이보다 복잡하고, 환경에 대한 구체화가 잘 되어있지 않은 (자율 주행 환경은 안전, 편안함 그리고 효율성이 균형을 이뤄야 함) 경우에는 적합한 보상함수의 설계가 어려워질 수 있다.</p>

<p>모방학습 방법은 전문가의 시연으로부터 직접적으로 학습함으로써 이러한 문제를 완화할 수 있는 가능성을 제시하며, 넓은 범위의 문제들에서 성공적인 결과를 보이고 있다. 그것들 중, GAIL은 model-free인 Imitation Learning 방법으로 굉장히 효과적이며 상대적으로 높은 차원의 환경에까지 scaling이 잘 될 수 있다. GAIL을 학습시키는 과정은 고정된 시뮬레이션 환경에서 전문가의 시연과 비슷한 행동을 생성해내는 생성 모델 즉, stochastic policy를 만드는 것으로도 생각될 수 있다. 이러한 유사성은 GAN에서와 같은 방식으로 Discriminator(구별자)를 통해 expert trajectory들과의 구별을 jointly하게 학습시키는 과정으로 얻어진다.</p>

<p>모방학습에서는 주로 사람에게서 얻어진 시연 데이터를 사용하는데, 이러한 시연들간에는 명확한 차이가 존재한다. 가령 이러한 시연들은 여러 전문가들로부터 수집되었을 수 있으며, 각각의 전문가는 서로 다른 policy를 가졌을 것이다. 시뮬레이션 환경이 감지하지 못하는 이러한 차이들에 대한 외부 잠재 요인또한 관찰된 행동들에 명확한 영향을 줄 수 있다 (이 부분은 솔직히 무슨 말인지 모르겠다). 가령 전문가 시연은 서로 다른 스킬과 습관을 가진 사용자로부터 수집되었을 수 있다. 본 논문의 목표는 전문가의 시연 아래 내제된 차이들에 대한 잠재 요인을 자동적으로 찾아 분해할 수 있는 모방학습 프레임워크를 개발하는 것이다. Reference [14]에서 이미지 생성 모델로부터 얻어진 style, shape 그리고 color를 분해했던 것처럼 여기서도 비지도 학습 방식으로 사람의 시연으로부터 유사한 해석가능한 컨셉을 자동적으로 학습해보고자 하는 것이다.</p>

<p>본 논문에서는 동적인 환경의 trajectory를 생성할 수 있는 잠재 변수 생성 모델을 학습할 수 있는 새로운 방법을 소개한다 (MDP 상의 상태, 행동의 pair).</p>

<h1 id="2-background">2. Background</h1>

<h1 id="3-interpretable-imitation-learning-through-visual-input">3. Interpretable Imitation Learning through Visual Input</h1>

<p><br /><br /></p>

<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="ybkim95" data-color="#FFDD00" data-emoji="" data-font="Comic" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#000000" data-coffee-color="#ffffff"></script>

:ET